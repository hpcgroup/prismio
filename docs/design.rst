***************
Design Overview
***************

Basic Idea and Data Structure
=============================

The code is made of three main part: reader, recorder dataframe, and multiple recorder 
dataframe handler. The basic idea is to collect useful information from Recorder and 
put them into pandas dataframes. Then provide interfaces that do common data manipulations
that are useful for users. 

For one run profiled by Recorder, the code will create a dataframe where each row
corresponds to a record in Recorder, which is essentially a function call.
The row contains the rank that calls the function, function id, function name,
start time, end time, elapsed time, argument counts, argument values, the file name 
it operates on (if any), and the file descripter it returns (if any).

User can use reader classes to read Recorder trace files. The reader first calls the
original recorder reader, then the reader use it to create the dataframe and a wrapper
class (RecorderDataFrame) that provides data manipulation interfaces. After that, 
user will play with this wrapper class.

To analyze multiple runs, user can create a multiple dataframe handler and pass in a 
list of RecorderDataFrame of each run. The handler provides interfaces that can do 
aggregated data operations.

RecorderDataReader
==================

This is the reader class that utilizes original recorder reader and returns a RecorderDataFrame.
It takes log directory as the parameter, uses it to create a RecorderReader. The RecorderReader
will have all useful information but in a unstructured way. 

The class first the list of all records and sorts them in the order of start time. 

Since some I/O functions takes file descripter as argument instead of the file name, it needs to 
go through the sorted records to figure out the file name this I/O function works with. The idea
is to create a map between file descripters and file names. Before using a fd, there should be 
functions like ``open`` to create the fd, and such functions will have file name in their arguments.
So this class knows the fd maps to a certain file name. Then later it can add file names to other 
records that only have fd info.

Finally, it create a dataframe and put above information into rows of it. Then it use the
dataframe to initialize a wrapper RecorderDataFrame object.

Functions
^^^^^^^^^

``sort_records(self)``

Sort the records in order of start time

``get_fd_to_file_name(self, records, np, func_id_to_name)``

Go through sorted records, check special I/O functions. According to the function type, it adds
file names to the map or find file names for records using the map. It finally returns the map

``add_rows(self, df, records)``

Add information of each record to a row in the dataframe

``read(self)``

Create and return the RecorderDataReader object.

RecorderDataFrame
==================

The main data structure wrapper. It contains the dataframe generated by the reader class and 
provides several functions to handle the data.

Functions
^^^^^^^^^

``from_recorder(log_dir)``

Call the reader class to get a RecorderDataFrame object with dataframe for this log_dir.

``filter(self, my_lambda)``

Filter the dataframe with given lambda function and return a new RecorderDataFrame.

``get_record_count(self)``

Return an integer that is the number of records in the whole run. 

``get_record_count_each_rank``

Return a list in which element i is the number of records in rank i.

``get_nonzero_function_count``

Return a dictionary that maps function id to the time of this function is called. Only include
functions that are actually called (nonzero counts)

``get_function_count(self)``

Return a list, in which element i is the time of the function i is called, including 0.

``get_nonzero_function_count_each_rank(self)``

Return a list of dictionaries. Dictionary i maps function id in rank i to the time it is called.

``get_function_count_each_rank(self)``

Return a list of list. List i contains funcion counts for rank i.

``get_file_access_count``

Return a dictionary that maps file name to the time of this file is operated by a function. 

``def get_total_file_access_count(self)``

Return the number of file accesses of the whole run.

``get_file_access_count_each_rank(self)``

Return a list of dictionary. Dictionary i maps maps file name to the time of this file is 
operated by functions in rank i.

``get_total_file_access_count_each_rank(self)``

Return a list where element i is the number of file accesses of the whole run of rank i.

``get_files(self)``

Return a list of all file names accessed by this run.

``get_files_each_ranks(self)``

Return a list, where element i is a list of file names accessed by rank i.

``get_total_file_count(self)``

Return the number of files accessed in the whole run.

``get_total_file_count_each_rank(self)``

Return a list where element i is the number of files accessed by rank i.

``get_total_function_time(self)``

Return the total function time of the whole run.

``get_nonzero_function_time(self)``

Return a dictionary that maps function id to its run time in the whole run.

``get_function_time(self)``

Return a list where element i is the run time of function i.

``get_total_function_time_each_rank(self)``

Return a list where element i is the total function time of rank initialize

``get_nonzero_function_time_each_rank(self)``

Return a list of dictionary. Dictionary i maps function id to its run time in rank i.

``get_function_time_each_rank(self)``

Return a list of list. List i contains runtime of all functions in rank i.

MultiRecorderDFHandler
======================

This class takes in multiple RecorderDataReaders and do aggregated data operations on them. 
Functions in this class mainly extract a feature and aggregate it to a new dataframe

Functions
^^^^^^^^^

``get_record_count_aggregated_by_logs(self)``

Return a dataframe where each row is the record count of each rank in a certain run. Row index
is log_dir and column index is rank number.

``get_record_count_aggregated_by_ranks(self)``

Transpose of the above

``get_average_record_count_each_rank(self)``

Return a list where element i is the average number of records for rank i of all runs.

``get_file_count_aggregated_by_logs(self)``

Return a dataframe. Row index is log_dir and column index is rank number. Each row is the number
of files operated of each rank in this run.

``get_file_count_aggregated_by_ranks(self)``

Transpose of the above

``get_function_count_aggregated_by_logs(self)``

Return a dataframe. Row index is log_dir and column index is function name. Each row is the number
of the function is called for each function in this run.

``get_function_count_aggregated_by_functions(self)``

Transpose of the above

``get_nonzero_function_count_aggregated_by_functions(self)``

Return a dataframe. Row index is function name and column index is log_dir. Each row is the number 
of this function is called for each run. Only contains functions actually called at least once in
at least one run.

``get_nonzero_function_count_aggregated_by_logs(self)``

Transpose of the above

``get_function_time_aggregated_by_logs(self)``

Return a dataframe. Row index is log_dir and column index is function name. Each row is the number
of the runtime for each function in this run.

``get_function_time_aggregated_by_functions(self)``

Transpose of the above

``get_nonzero_function_time_aggregated_by_functions(self)``

Return a dataframe. Row index is function name and column index is log_dir. Each row is the runtime 
of this function for each run. Only contains functions actually called at least once in
at least one run.

``get_nonzero_function_time_aggregated_by_logs(self)``

Transpose of the above
