# Copyright 2020-2021 Parallel Software and Systems Group, University of
# Maryland. See the top-level LICENSE file for details.
#
# SPDX-License-Identifier: MIT

"""
The prismio.io_frame module provides the IOFrame class for structured data
structure and flexible api of tracing/profiling data generated by Recorder
or Darshan
"""

import dataclasses
import sys
import os

from pandas.core.frame import DataFrame
from typing import Callable, List, Dict, Optional
import numpy as np
import pandas as pd
from dataclasses import dataclass

import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns

@dataclass
class IOFrame:
    """
    Main class of the prism application. It holds I/O performance data 
    generated by I/O tools. It reorganizes the data into a Pandas.DataFrame,
    which contains useful information such as the start time of functions, 
    the files functions access to, etc. It also provides flexible api 
    functions for user to do analysis.
    """
    # the dataframe this IOFrame should have.
    dataframe: DataFrame
    # the dataframe containing metadata info, such as total runtime of each rank
    metadata: DataFrame

    @staticmethod
    def from_recorder(log_dir: str):
        """
        Read trace files from recorder and create the corresponding
        IOFrame object.

        Args:
            log_dir (str): path to the trace files directory of Recorder the user wants to analyze.

        Return:
            A IOFrame object corresponding to this trace files directory.

        """
        from prismio.readers.recorder_reader import RecorderReader
        return RecorderReader(log_dir).read()

    def copy(self):
        """
        Make a deep copy of this IOFrame

        """
        return IOFrame(self.dataframe.copy(deep=True), self.metadata.copy(deep=True))
    
    def filter(self, my_lambda): 
        """
        Create a new IOFrame based on the filter function the user provides.

        Args:
            my_lambda (function): filtering function. For example, np.sum, np.sort.

        Return:
            A new IOFrame object with a new filtered dataframe.

        """
        dataframe = self.dataframe[self.dataframe.apply(my_lambda, axis = 1)].copy()
        dataframe = dataframe.reset_index()
        dataframe = dataframe.drop('index', axis=1)
        print("Warning: filtering dataframe may cause inconsistency in metadata!")
        return IOFrame(dataframe, self.metadata)

    def groupby_aggregate(self, groupby_columns: List[str], rank: Optional[list]=None, agg_dict: Optional[dict]=None, filter: Optional[Callable[..., bool]]=None, drop: Optional[bool]=False, dropna: Optional[bool]=False):
        """
        Return a dataframe after groupby and aggregate operations on the dataframe of this IOFrame.

        Args:
            groupby_columns (list of strings): the column names the user wants to groupby.
            rank (list): Ranks the user wants to keep. Other ranks will be filtered out in the result.
                If it is None, then keep all ranks.
            agg_dict (dictionary): aggregation functions for some columns
            filter (function): function used to filter rows before groupby
            drop: If true, drop columns not specified in agg_dict. Otherwise keep all columns in the result.
            dropna: used by groupby, decide whether to include NaN as a group.

        Return:
            A dataframe after groupby and aggregate operations on the dataframe of this IOFrame.

        """
        # default aggregation functions for all columns
        default_agg_dict = {
            'rank': lambda x: x.iloc[0],
            'function_id': lambda x: x.iloc[0],
            'function_name': lambda x: x.iloc[0],
            'tstart': np.min,
            'tend': np.max,
            'time': np.sum,
            'arg_count': lambda x: x.iloc[0],
            'args': lambda x: x.iloc[0],
            'return_value': lambda x: x.iloc[0],
            'file_name': lambda x: x.iloc[0],
            'io_volume': np.sum
        }

        # Filter out not specified ranks. Make a deep copy and groupby_agg on it,
        # so self.dataframe is not changed.
        dataframe = self.dataframe
        if rank is not None:
            dataframe = self.dataframe[self.dataframe['rank'].isin(rank)].copy()
            dataframe = dataframe.reset_index()
            dataframe = dataframe.drop('index', axis=1)
            # dataframe = dataframe.copy(deep=True)
        if filter is not None:
            dataframe = dataframe[self.dataframe.apply(filter, axis = 1)].copy()
            dataframe = dataframe.reset_index()
            dataframe = dataframe.drop('index', axis=1)

        groupby_obj = dataframe.groupby(groupby_columns, dropna=dropna)

        # if agg_dic is None, use the default agg_dict
        if agg_dict is None:
            agg_dataframe = groupby_obj.agg(default_agg_dict)
            return agg_dataframe
        
        # if not, make sure columns contain keys in agg_dict
        for key in agg_dict:
            if key not in self.dataframe.columns:
                raise KeyError("Specified column does not exist in the dataframe!")
        
        # if drop other columns, directly apply agg_dict
        if drop:
            agg_dataframe = groupby_obj.agg(agg_dict)
        # else replace functions in default agg_dict with user specified ones,
        # then apply default agg_dict
        else:
            for key in agg_dict:
                default_agg_dict[key] = agg_dict[key]
            agg_dataframe = groupby_obj.agg(default_agg_dict)
        
        return agg_dataframe
    
    def file_summary(self):
        """
        Organize file information (num of access, io_volume, time spent) to a dataframe
        
        Args:

        Return:
            A multi-index dataframe containing information of a file operated by a rank for all files and ranks.

        """
        dataframe = self.groupby_aggregate(['file_name','rank','function_type'], agg_dict={'file_name': 'count', 'io_volume': np.sum, 'time': np.sum}, drop=True, dropna=True)
        dataframe = dataframe.rename(columns={'file_name': 'file_access_count'})
        return dataframe

    def file_count(self, rank: Optional[list]=None, agg_function: Optional[Callable]=None, filter: Optional[Callable[..., bool]]=None, dropna: Optional[bool]=False):
        """
        Depending on input arguments, return the number of files for ranks selected by the
        user in the form of a DataFrame. It contains the number of files touched (read or written) 
        by these ranks. If agg_function is specified, then it will apply the function to 
        the result.

        Args:
            rank (None or a list): user selected ranks to get file count.
            agg_function: (function): aggregation function applying on the result.

        Return:
            If rank == None and agg_function == None, it returns a Pandas DataFrame 
            that contains the number of files for all ranks.
            If rank != None and agg_function == None, it returns a Pandas DataFrame 
            that contains the number of files for the listed ranks.
            If rank == None and agg_function != None, it returns a number from applying
            the function on the dataframe. For example, if agg_function = np.mean, it
            returns the average number of files of all ranks.
            If rank != None and agg_function != None, it returns a number from applying
            the function on the dataframe for listed ranks. For example, if rank =
            [1,3,5], agg_function = np.mean, it returns the average number of files 
            of all rank 1, 3, 5.

        """

        # result=self.metadata['num_files']
        # if rank is not None:
        #     result = result.filter(rank, axis=0)
        # if agg_function is None:
        #     return result
        # else:
        #     return agg_function(result)

        # groupby rank, then count the number of unique file names
        dataframe = self.groupby_aggregate(['rank'], rank=rank, agg_dict={'file_name': 'nunique'}, filter=filter, drop=True, dropna=dropna)
        dataframe = dataframe.rename(columns={'file_name': 'file_count'})

        if agg_function == None:
            return dataframe
        # apply agg_function if it's not None
        else:
            return agg_function(dataframe)

    def file_access_count(self, rank: Optional[list]=None, agg_function: Optional[Callable]=None, rank_major:Optional[bool]=False, filter: Optional[Callable[..., bool]]=None, dropna: Optional[bool]=False, complement: Optional[bool]=False):
        """
        Depending on input arguments, return the number of accesses of each file in each rank
        selected by the user in the form of a DataFrame. If agg_function is specified, then it 
        will apply the function to the result.
        The function first group the dataframe by file name. Then it goes through each group. 
        And for each group, the function groups it by rank and aggregates to find the count for
        each rank. Then it filters ranks the user wants, and put result to a dictionary. After
        going through all file name groups. It use the dictionary to create a dataframe. If
        agg_function is specified, it applies the function on the dataframe.

        Args:
            rank (None or a list): user selected ranks to get file count.
            agg_function: (function): aggregation function applying on the result.

        Return:
            If rank == None and agg_function == None, it returns a Pandas DataFrame in which
            the columns are file names, rows are ranks, and the values are the number of accesses
            for that file and rank.
            If rank != None and agg_function == None, it returns a similar Pandas DataFrame but
            with only user specified ranks (rows).
            If rank == None and agg_function != None, it returns a Pandas Series that has the number
            from applying the function on each file name across all ranks. For example, if agg_function = 
            np.mean, it returns a series containing the average number of accesses for this file across 
            all ranks.
            If rank != None and agg_function != None, it returns a Pandas Series that has the number
            from applying the function on each file name across selected ranks. For example, if agg_function = 
            np.mean, rank = [1, 3, 5], it returns a series containing the average number of accesses for 
            this file across rank 1, 3, 5.

        """
        
        # groupby file name and rank, then count the number of each file name
        if rank_major:
            dataframe = self.groupby_aggregate(['rank', 'file_name'], rank=rank, agg_dict={'file_name': 'count'}, filter=filter, drop=True, dropna=dropna)
        else:
            dataframe = self.groupby_aggregate(['file_name', 'rank'], rank=rank, agg_dict={'file_name': 'count'}, filter=filter, drop=True, dropna=dropna)
        
        dataframe = dataframe.rename(columns={'file_name': 'file_access_count'})
        
        if complement:
            new_index = pd.MultiIndex.from_product(dataframe.index.levels)
            dataframe = dataframe.reindex(new_index).fillna(0)

        if agg_function is None:
            return dataframe
        # group by file names and apply agg_function over ranks if it's not None
        else:
            dataframe = dataframe.groupby(level=[0]).agg({'file_access_count': agg_function})
            return dataframe
            
    def function_count(self, rank: Optional[list]=None, agg_function: Optional[Callable]=None, rank_major:Optional[bool]=False, filter: Optional[Callable[..., bool]]=None, dropna: Optional[bool]=False, complement: Optional[bool]=False):
        """
        Identical to the previous one. Only instead of groupby file, it groupby function.

        Args:
            rank (None or a list): user selected ranks to get file count.
            agg_function: (function): aggregation function applying on the result.

        Return:
            Identical structure to the previous one, except the value here is the number of function
            calls for a function in selected ranks. Or avg/min/max accross selected ranks depending 
            on the agg_function

        """
        
        # groupby function name and rank, then count the number of each function name
        if rank_major:
            dataframe = self.groupby_aggregate(['rank', 'function_name'], rank=rank, agg_dict={'function_name': 'count'}, filter=filter, drop=True, dropna=dropna)
        else:
            dataframe = self.groupby_aggregate(['function_name', 'rank'], rank=rank, agg_dict={'function_name': 'count'}, filter=filter, drop=True, dropna=dropna)
        
        dataframe = dataframe.rename(columns={'function_name': 'function_count'})
        
        if complement:
            new_index = pd.MultiIndex.from_product(dataframe.index.levels)
            dataframe = dataframe.reindex(new_index).fillna(0)

        # group by function name and apply agg_function over ranks if it's not None
        if agg_function is None:
            return dataframe
        else:
            dataframe = dataframe.groupby(level=[0]).agg({'function_count': agg_function})
            return dataframe

    def function_time(self, rank: Optional[list]=None, agg_function: Optional[Callable]=None, rank_major:Optional[bool]=False, filter: Optional[Callable[..., bool]]=None, dropna: Optional[bool]=False, complement: Optional[bool]=False):
        """
        Identical to the previous one. Only instead of aggregating by count, it 
        aggregating by sum of the time.

        Args:
            rank (None or a list): user selected ranks to get file count.
            agg_function: (function): aggregation function applying on the result.

        Return:
            Identical structure to the previous one, except the value here is the total time of function
            in selected ranks. Or avg/min/max accross selected ranks depending on the agg_function

        """
       
        # groupby function name and rank, then sum the runtime
        if rank_major: 
            dataframe = self.groupby_aggregate(['rank', 'function_name'], rank=rank, agg_dict={'time': 'sum'}, filter=filter, drop=True, dropna=dropna)
        else:
            dataframe = self.groupby_aggregate(['function_name', 'rank'], rank=rank, agg_dict={'time': 'sum'}, filter=filter, drop=True, dropna=dropna)
        
        if complement:
            new_index = pd.MultiIndex.from_product(dataframe.index.levels)
            dataframe = dataframe.reindex(new_index).fillna(0)

        if agg_function is None:
            return dataframe
        # group by function name and apply agg_function over ranks if it's not None
        else:
            dataframe = dataframe.groupby(level=[0]).agg({'time': agg_function})
            return dataframe

    def function_count_by_library(self, rank: Optional[list]=None, agg_function: Optional[Callable]=None, rank_major:Optional[bool]=False, filter: Optional[Callable[..., bool]]=None, dropna: Optional[bool]=False, complement: Optional[bool]=False):
        """
        Count the number of function calls from mpi, hdf5 and posix. Same implementation to previous
        ones. But it first check the library for each function call, and then groupby the library.

        Args:
            rank (None or a list): user selected ranks to get file count.
            agg_function: (function): aggregation function applying on the result.

        Return:
            Identical structure to the previous one, except the value here is the number of function
            calls of a library in selected ranks. Or avg/min/max accross selected ranks depending on 
            the agg_function

        """
        
        # helper function to check library for a given function
        def check_library(function):
            if 'H5' in function:
                return 'hdf5'
            elif 'MPI' in function:
                return 'mpi'
            else:
                return 'posix'

        # check library for each row and put result into a new column 
        self.dataframe['library'] = self.dataframe['function_name'].apply(lambda function: check_library(function))
        
        # groupby library name and rank, then count the number of functions in each library
        if rank_major:
            dataframe = self.groupby_aggregate(['rank', 'library'], rank=rank, agg_dict={'library': 'count'}, filter=filter, drop=True, dropna=dropna)
        else:
            dataframe = self.groupby_aggregate(['library', 'rank'], rank=rank, agg_dict={'library': 'count'}, filter=filter, drop=True, dropna=dropna)
        # drop the new column to maintain the original dataframe
        self.dataframe.drop(['library'], axis=1, inplace=True)
        
        dataframe = dataframe.rename(columns={'library': 'library_call_count'})
        
        if complement:
            new_index = pd.MultiIndex.from_product(dataframe.index.levels)
            dataframe = dataframe.reindex(new_index).fillna(0)

        # group by library name and apply agg_function over ranks if it's not None
        if agg_function is None:
            return dataframe
        else:
            dataframe = dataframe.groupby(level=[0]).agg({'library_call_count': agg_function})
            return dataframe

    def io_volume(self, unit='auto', rank: Optional[list]=None, agg_function: Optional[Callable]=None, rank_major:Optional[bool]=False, filter: Optional[Callable[..., bool]]=None, dropna: Optional[bool]=False, complement: Optional[bool]=False):
        """
        Compute I/O volumes at different granularities. By default it returns the io volume of the whole run.
        If by_rank is True, return a dataframe where each row corresponds to a rank and has the io volumn 
        for it. If by_file is True, return a dataframe where each row corresponds to a file and has its io 
        volumn. If both are Ture, return a multi-index dataframe where each row corresponds to a file accessed
        by a rank and its io_volumn

        Args:
            by_rank (bool): Show io volumn of each rank if true.
            by_file (bool): Show io volumn of each file if true.

        Return:
            A dataframe or a number depending on the granularity.

        """
        if rank_major: 
            dataframe = self.groupby_aggregate(['rank', 'file_name'], rank=rank, agg_dict={'io_volume': 'sum'}, filter=filter, drop=True, dropna=dropna)
        else:
            dataframe = self.groupby_aggregate(['file_name', 'rank'], rank=rank, agg_dict={'io_volume': 'sum'}, filter=filter, drop=True, dropna=dropna)
        
        if complement:
            new_index = pd.MultiIndex.from_product(dataframe.index.levels)
            dataframe = dataframe.reindex(new_index).fillna(0)

        if unit == 'auto':
            avg_io_volume = dataframe['io_volume'].mean()
            if avg_io_volume < 100:
                unit = 'B'
            elif avg_io_volume < 100000:
                unit = 'KB'
                dataframe['io_volume'] = dataframe['io_volume'] / 1000
            elif avg_io_volume < 100000000:
                unit = 'MB'
                dataframe['io_volume'] = dataframe['io_volume'] / 1000000
            else:
                unit = 'GB'
                dataframe['io_volume'] = dataframe['io_volume'] / 1000000000
        elif unit == 'B':
            pass
        elif unit == 'KB':
            dataframe['io_volume'] = dataframe['io_volume'] / 1000
        elif unit == 'MB':
            dataframe['io_volume'] = dataframe['io_volume'] / 1000000
        elif unit == 'GB':
            dataframe['io_volume'] = dataframe['io_volume'] / 1000000000
        else:
            raise KeyError("unit can only be: auto, B, KB, MB, GB")
        
        dataframe.rename({'io_volume': 'io_volume (' + unit + ')'}, axis=1, inplace=True)

        if agg_function is None:
            return dataframe
        # group by function name and apply agg_function over ranks if it's not None
        else:
            dataframe = dataframe.groupby(level=[0]).agg({'io_volume (' + unit + ')': agg_function})
            return dataframe

    def io_time(self, io_type: str='write,read,meta', rank: Optional[list]=None, agg_function: Optional[Callable]=None, rank_major:Optional[bool]=False, filter: Optional[Callable[..., bool]]=None, dropna: Optional[bool]=False, complement: Optional[bool]=False):
        """
        Compute the percentage of time spent in a type of functions.
        By default it returns the percentage of io time vs the whole run.
        If by_rank is True, return a dataframe where each row corresponds to a rank and has the time spent in
        function_type vs time spent in that rank. If by_file is True, return a dataframe where each row corresponds 
        to a file and has its time spent in function_type vs the total runtime (only meaning for if function_type is io) 
        If both are Ture, return a multi-index dataframe where each row corresponds to a file accessed
        by a rank and its time spent in function_type vs time spent in that rank. (only meaning for if function_type is io) 

        Args:
            function_type (str): the function type 
            by_rank (bool): Show io volumn of each rank if true.
            by_file (bool): Show io volumn of each file if true.

        Return:
            A dataframe or a number depending on the granularity.

        """
        if filter is None:
            filter = lambda x: True

        if rank_major: 
            dataframe = self.groupby_aggregate(['rank', 'file_name'], rank=rank, agg_dict={'time': 'sum'}, filter=filter and (lambda x: x['function_type'] in io_type), drop=True, dropna=dropna)
        else:
            dataframe = self.groupby_aggregate(['file_name', 'rank'], rank=rank, agg_dict={'time': 'sum'}, filter=filter and (lambda x: x['function_type'] in io_type), drop=True, dropna=dropna)
       
        if complement:
            new_index = pd.MultiIndex.from_product(dataframe.index.levels)
            dataframe = dataframe.reindex(new_index).fillna(0)

        if agg_function is None:
            dataframe = dataframe.reset_index()
            dataframe = dataframe.merge(self.metadata.set_index('rank')[['time']], on='rank', suffixes=('_\'' + io_type + '\'_this_rank', '_total_this_rank'))
            dataframe['percentage'] = dataframe['time_\'' + io_type + '\'_this_rank'] / dataframe['time_total_this_rank']
            if rank_major:
                dataframe = dataframe.set_index(['rank', 'file_name'])
            else:
                dataframe = dataframe.set_index(['file_name', 'rank'])
            return dataframe
        else:
            dataframe = dataframe.groupby(level=[0]).agg({'time': agg_function})
            dataframe.columns = dataframe.columns.to_flat_index()
            if rank_major: 
                dataframe = dataframe.merge(self.metadata.set_index('rank')[['time']], on='rank')
                dataframe.rename(columns={"time": "time_total_this_rank"}, inplace=True)
                # print(dataframe)
                for column in dataframe.columns:
                    if column != 'rank' and column != 'time_total_this_rank':
                        dataframe[column[0] + '-' + column[1] + '(percentage)'] = dataframe[column] / dataframe['time_total_this_rank']
                return dataframe
            else:
                total_runtime = self.metadata['end_timestamp'].max() - self.metadata['start_timestamp'].min()
                for column in dataframe.columns:
                    dataframe[column[0] + '-' + column[1] + '(percentage)'] = dataframe[column] / total_runtime
                dataframe['total_runtime'] = total_runtime
                return dataframe

    def shared_files(self, dropna: Optional[bool]=False):
        """
        Organize shared file information to a dataframe. Besides num of access, io_volume, time spent, include number
        of ranks that share the file
        
        Args:

        Return:
            A multi-index dataframe containing information of a file shared by some ranks for all files.

        """
        dataframe = self.groupby_aggregate(['file_name', 'function_type'], agg_dict={'rank': 'unique', 'file_name': 'count', 'io_volume': np.sum}, drop=True, dropna=dropna)
        dataframe = dataframe.rename(columns={'file_name': 'file_access_count'})
        dataframe = dataframe.rename(columns={'rank': 'shared_ranks'})
        dataframe['num_ranks'] = dataframe.apply(lambda x: len(x.shared_ranks), axis=1)
        return dataframe

    def is_shared_io(self):
        shared_files = self.shared_files(dropna=True)
        shared_files = shared_files.reset_index()
        shared_files = shared_files[shared_files.apply(lambda x: self.is_keep(x['file_name']), axis = 1)]
        shared_files['num_ranks'] = shared_files['shared_ranks'].apply(lambda x: len(x))
        if shared_files['num_ranks'].max() > 1:
            return True
        else:
            return False

    def io_bandwidth(self, unit='auto', rank: Optional[list]=None, agg_function: Optional[Callable]=None, rank_major:Optional[bool]=True, filter: Optional[Callable[..., bool]]=None, dropna: Optional[bool]=False, complement: Optional[bool]=False):
        if rank_major: 
            dataframe = self.groupby_aggregate(['rank', 'file_name'], rank=rank, agg_dict={'io_volume': 'sum', 'time': 'sum'}, filter=filter and (lambda x: x['function_type'] in 'write,read,other_io' and self.is_keep(x['file_name'])), drop=True, dropna=dropna)
        else:
            dataframe = self.groupby_aggregate(['file_name', 'rank'], rank=rank, agg_dict={'io_volume': 'sum', 'time': 'sum'}, filter=filter and (lambda x: x['function_type'] in 'write,read,other_io' and self.is_keep(x['file_name'])), drop=True, dropna=dropna)
        
        if complement:
            new_index = pd.MultiIndex.from_product(dataframe.index.levels)
            dataframe = dataframe.reindex(new_index).fillna(0)

        dataframe['io_bandwidth'] = dataframe['io_volume'] / dataframe['time']

        if unit == 'auto':
            avg_io_bandwidth = dataframe['io_bandwidth'].mean()
            if avg_io_bandwidth < 100:
                unit = 'B/s'
            elif avg_io_bandwidth < 100000:
                unit = 'KB/s'
                dataframe['io_bandwidth'] = dataframe['io_bandwidth'] / 1000
            elif avg_io_bandwidth < 100000000:
                unit = 'MB/s'
                dataframe['io_bandwidth'] = dataframe['io_bandwidth'] / 1000000
            else:
                unit = 'GB/s'
                dataframe['io_bandwidth'] = dataframe['io_bandwidth'] / 1000000000
        elif unit == 'B/s':
            pass
        elif unit == 'KB/s':
            dataframe['io_bandwidth'] = dataframe['io_bandwidth'] / 1000
        elif unit == 'MB/s':
            dataframe['io_bandwidth'] = dataframe['io_bandwidth'] / 1000000
        elif unit == 'GB/s':
            dataframe['io_bandwidth'] = dataframe['io_bandwidth'] / 1000000000
        else:
            raise KeyError("unit can only be: auto, B/s, KB/s, MB/s, GB/s")

        dataframe.rename({'io_bandwidth': 'io_bandwidth (' + unit + ')'}, axis=1, inplace=True)

        dataframe.drop(['io_volume', 'time'], axis=1, inplace=True)

        if agg_function is None:
            return dataframe
        else:
            dataframe = dataframe.groupby(level=[0]).agg({'io_bandwidth (' + unit + ')': agg_function})
            return dataframe

    def total_io_bandwidth(self, unit='MB/s'):
        dataframe = self.io_bandwidth(unit=unit, agg_function='sum')
        column_name = dataframe.columns[0]
        total_io_bandwidth = {}
        total_io_bandwidth['avg'] = dataframe[column_name].mean()
        total_io_bandwidth['min'] = dataframe[column_name].min()
        total_io_bandwidth['max'] = dataframe[column_name].max()
        return total_io_bandwidth

    def time_distribution(self, rank: Optional[list]=None, filter: Optional[Callable[..., bool]]=None, ratio=False):
        if filter is None:
            filter = lambda x: True
        
        io_time = self.groupby_aggregate(['rank'], rank=rank, agg_dict={'time': 'sum'}, filter=filter and (lambda x: x['function_type'] in 'write,read,meta'), drop=True)
        comm_time = self.groupby_aggregate(['rank'], rank=rank, agg_dict={'time': 'sum'}, filter=filter and (lambda x: x['function_type'] == 'comm'), drop=True)
        
        io_time.rename(columns={'time': 'io_time'}, inplace=True)
        comm_time.rename(columns={'time': 'comm_time'}, inplace=True)

        distribution = pd.concat([io_time, comm_time['comm_time']], axis=1)
        distribution["compute_time"] = ""
        distribution = pd.concat([distribution, self.metadata['time']], axis=1)
        distribution.rename(columns={'time': 'total_time'}, inplace=True)
        distribution['compute_time'] = distribution['total_time'] - distribution['io_time'] - distribution['comm_time']
        
        if ratio:
            distribution['io_time'] = distribution['io_time'] / distribution['total_time']
            distribution['comm_time'] = distribution['comm_time'] / distribution['total_time']
            distribution['compute_time'] = distribution['compute_time'] / distribution['total_time']
            distribution['total_time'] = distribution['total_time'] / distribution['total_time']

        return distribution
    
    def io_intensity(self, rank: Optional[list]=None, filter: Optional[Callable[..., bool]]=None):
        time_distribution = self.time_distribution(rank, filter)
        time_distribution['I/O Intensity'] = time_distribution['io_time'] / time_distribution['compute_time']
        time_distribution.drop(['io_time', 'comm_time', 'compute_time', 'total_time'], axis=1, inplace=True)
        return time_distribution

    def io_request_size_distribution(self, bins=[0, 1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000, float('inf')], bin_names=['<1K', '1K-10K', '10K-100K', '100K-1M', '1M-10M', '10M-100M', '100M-1G', '>1G']):
        dataframe = self.dataframe[self.dataframe['io_volume'] > 0].copy()
        result = dataframe.groupby(['rank', pd.cut(dataframe.io_volume, bins)]).size().unstack()
        result.set_axis(bin_names, axis=1, inplace=True)
        return result
    
    def io_request_bandwidth_distribution(self, bins=[0, 1000000, 10000000, 100000000, 1000000000, 10000000000, float('inf')], bin_names=['<1M/s', '1M/s-10M/s', '10M/s-100M/s', '100M/s-1G/s', '1G/s-10G/s', '>10G/s']):
        dataframe = self.dataframe[self.dataframe['io_volume'] > 0].copy()
        dataframe['io_bandwidth'] = dataframe['io_volume'] / dataframe['time']
        result = dataframe.groupby(['rank', pd.cut(dataframe.io_bandwidth, bins)]).size().unstack()
        result.set_axis(bin_names, axis=1, inplace=True)
        return result

    def io_request_size_timeline(self, unit='auto', rank: Optional[list]=None, style="scatter", separate_ranks=False, num_bins=10):
        dataframe = self.dataframe[self.dataframe['io_volume'] > 0].copy()
        plt.figure()

        if unit == 'auto':
            avg_io_volume = dataframe['io_volume'].mean()
            if avg_io_volume < 100:
                unit = 'B'
            elif avg_io_volume < 100000:
                unit = 'KB'
                dataframe['io_volume'] = dataframe['io_volume'] / 1000
            elif avg_io_volume < 100000000:
                unit = 'MB'
                dataframe['io_volume'] = dataframe['io_volume'] / 1000000
            else:
                unit = 'GB'
                dataframe['io_volume'] = dataframe['io_volume'] / 1000000000
        elif unit == 'B':
            pass
        elif unit == 'KB':
            dataframe['io_volume'] = dataframe['io_volume'] / 1000
        elif unit == 'MB':
            dataframe['io_volume'] = dataframe['io_volume'] / 1000000
        elif unit == 'GB':
            dataframe['io_volume'] = dataframe['io_volume'] / 1000000000
        else:
            raise KeyError("unit can only be: auto, B, KB, MB, GB")
        
        dataframe.rename({'io_volume': 'io_volume (' + unit + ')'}, axis=1, inplace=True)

        if style == "scatter":
            if separate_ranks:
                sns.scatterplot(x='tstart', y='io_volume (' + unit + ')', hue='rank', data=dataframe)
            else:
                sns.scatterplot(x='tstart', y='io_volume (' + unit + ')', data=dataframe)
        elif style == "line":
            if separate_ranks:
                sns.lineplot(x='tstart', y='io_volume (' + unit + ')', hue='rank', data=dataframe)
            else:
                sns.lineplot(x='tstart', y='io_volume (' + unit + ')', data=dataframe)
        elif style == "hist":
            bins = np.linspace(dataframe['tstart'].min(), dataframe['tstart'].max(), num_bins)
            if separate_ranks:
                dataframe = dataframe.groupby(['rank', pd.cut(dataframe.tstart, bins, include_lowest=True)])['io_volume (' + unit + ')'].sum().unstack().T
            else:
                dataframe = dataframe.groupby([pd.cut(dataframe.tstart, bins, include_lowest=True)])['io_volume (' + unit + ')'].sum().T
            dataframe.plot.bar()
        elif style == "interval":
            if separate_ranks:
                raise KeyError("Not implemented yet")
            else:
                dataframe = dataframe.loc[dataframe.index.repeat(3)].copy()
                dataframe.reset_index(inplace=True)
                dataframe.loc[1::3, 'tstart'] = dataframe['tend']
                dataframe.loc[2::3, 'tstart'] = float('nan')
                dataframe.loc[2::3, 'io_volume (' + unit + ')'] = float('nan')
                plt.plot(dataframe.tstart, dataframe['io_volume (' + unit + ')'], linewidth=2)
        else:
            raise KeyError("No " + style + "option for style")

    def io_request_bandwidth_timeline(self, unit='auto', rank: Optional[list]=None, style="scatter", separate_ranks=False, num_bins=10):
        dataframe = self.dataframe[self.dataframe['io_volume'] > 0].copy()
        dataframe['io_bandwidth'] = dataframe['io_volume'] / dataframe['time']

        if unit == 'auto':
            avg_io_bandwidth = dataframe['io_bandwidth'].mean()
            if avg_io_bandwidth < 100:
                unit = 'B/s'
            elif avg_io_bandwidth < 100000:
                unit = 'KB/s'
                dataframe['io_bandwidth'] = dataframe['io_bandwidth'] / 1000
            elif avg_io_bandwidth < 100000000:
                unit = 'MB/s'
                dataframe['io_bandwidth'] = dataframe['io_bandwidth'] / 1000000
            else:
                unit = 'GB/s'
                dataframe['io_bandwidth'] = dataframe['io_bandwidth'] / 1000000000
        elif unit == 'B/s':
            pass
        elif unit == 'KB/s':
            dataframe['io_bandwidth'] = dataframe['io_bandwidth'] / 1000
        elif unit == 'MB/s':
            dataframe['io_bandwidth'] = dataframe['io_bandwidth'] / 1000000
        elif unit == 'GB/s':
            dataframe['io_bandwidth'] = dataframe['io_bandwidth'] / 1000000000
        else:
            raise KeyError("unit can only be: auto, B/s, KB/s, MB/s, GB/s")

        dataframe.rename({'io_bandwidth': 'io_bandwidth (' + unit + ')'}, axis=1, inplace=True)

        plt.figure()

        if style == "scatter":
            if separate_ranks:
                sns.scatterplot(x='tstart', y='io_bandwidth (' + unit + ')', hue='rank', data=dataframe)
            else:
                sns.scatterplot(x='tstart', y='io_bandwidth (' + unit + ')', data=dataframe)
        elif style == "line":
            if separate_ranks:
                sns.lineplot(x='tstart', y='io_bandwidth (' + unit + ')', hue='rank', data=dataframe)
            else:
                sns.lineplot(x='tstart', y='io_bandwidth (' + unit + ')', data=dataframe)
        elif style == "hist":
            bins = np.linspace(dataframe['tstart'].min(), dataframe['tstart'].max(), num_bins)
            if separate_ranks:
                dataframe = dataframe.groupby(['rank', pd.cut(dataframe.tstart, bins, include_lowest=True)])['io_bandwidth (' + unit + ')'].mean().unstack().T
            else:
                dataframe = dataframe.groupby([pd.cut(dataframe.tstart, bins, include_lowest=True)])['io_bandwidth (' + unit + ')'].mean().T
            dataframe.plot.bar()
        elif style == "interval":
            if separate_ranks:
                raise KeyError("Not implemented yet")
            else:
                dataframe = dataframe.loc[dataframe.index.repeat(3)].copy()
                dataframe.reset_index(inplace=True)
                dataframe.loc[1::3, 'tstart'] = dataframe['tend']
                dataframe.loc[2::3, 'tstart'] = float('nan')
                dataframe.loc[2::3, 'io_bandwidth (' + unit + ')'] = float('nan')
                plt.plot(dataframe.tstart, dataframe['io_bandwidth (' + unit + ')'], linewidth=2)
        else:
            raise KeyError("No " + style + "option for style")
        plt.xlabel('time (s)')
        plt.ylabel('I/O bandwidth (' + unit + ')')

    def timeline(self, rank: Optional[list]=None, filter=lambda x: True, style="scatter"):
        dataframe = self.dataframe[self.dataframe.apply(filter, axis = 1)].copy()
        groups = dataframe.groupby('function_name')
        # functions = list(dataframe['function_name'].unique())
        plt.figure()
        ax = plt.subplot(111)
        if style == "scatter":
            sns.scatterplot(x='tstart', y='rank', data=dataframe, hue='function_name')
        elif style == "interval":
            for name, group in groups:
                group = group.loc[group.index.repeat(3)].copy()
                group.reset_index(inplace=True)
                group.loc[1::3, 'tstart'] = group['tend']
                group.loc[2::3, 'tstart'] = float('nan')
                group.loc[2::3, 'rank'] = float('nan')
                plt.plot(group.tstart, group['rank'], linewidth=2, label=name)
            ax.legend(bbox_to_anchor=(1.04,1), loc="upper left")
        else:
            raise KeyError("No " + style + "option for style")
        
        plt.xlabel('time (s)')
        plt.ylabel('rank')

    def byteTo(self, value, unit='auto'):
        if unit == 'auto':
            if value < 100:
                unit = 'B'
            elif value < 100000:
                unit = 'KB'
            elif value < 100000000:
                unit = 'MB'
            else:
                unit = 'GB'

        if unit == 'B':
            pass
        elif unit == 'KB':
            value = value / 1024
        elif unit == 'MB':
            value = value / 1024 / 1024
        elif unit == 'GB':
            value = value / 1024 / 1024 / 1024
        else:
            raise KeyError("unit can only be: auto, B, KB, MB, GB")

        return str(value) + ' ' + unit

    def getAPI(self):
        def check_interface(function):
            if 'H5' in function and ('write' in function or 'read' in function):
                return 'HDF5'
            elif 'MPI' in function and ('write' in function or 'read' in function):
                return 'MPIIO'
            elif 'write' in function or 'read' in function:
                return 'POSIX'
            else:
                return 'Not IO'

        self.dataframe['I/O interface'] = self.dataframe['function_name'].apply(lambda function: check_interface(function))
        interface = self.dataframe.groupby('I/O interface')['function_name'].count()
        
        max = -1
        api = ''
        interface['POSIX'] = interface['POSIX'] - 2 * interface['MPIIO']

        for i in range(len(interface)):
            if interface[i] > max and interface.index[i] != 'Not IO':
                max = interface[i]
                api = interface.index[i]
        return api
    
    def is_keep(self, file_name):
        if file_name == None:
            return False
        if file_name != file_name: # check if it is NaN
            return False
        file_ignore = ['/dev/', '/etc', 'stdout', 'stdin', 'stderr']
        for ignore in file_ignore:
            if ignore in file_name:
                return False
        return True

    def getTransferSize(self):
        df = self.dataframe[self.dataframe.apply(lambda x: self.is_keep(x['file_name']), axis = 1)]

        transferSize = df['io_volume'].mean()
        return self.byteTo(transferSize)

    def isCollective(self):
        df = self.dataframe[self.dataframe['function_name'].str.contains('MPI')]
        df = df[df['function_name'].str.contains('read') | df['function_name'].str.contains('write')]
        collective = df[df['function_name'].str.contains('all') | df['function_name'].str.contains('ordered')]
        print(len(collective))
        print(len(df))
        return len(collective) / len(df) > 0.9

    def isFsyncPerWrite(self):
        count = 0
        df = self.dataframe[self.dataframe.apply(lambda x: self.is_keep(x['file_name']), axis = 1)]
        df = df[~df['function_name'].str.contains('MPI')]
        df = df[~df['function_name'].str.contains('HDF5')]

        for name, grp in df.groupby('rank'):
            prevRow = None
            for index, row in grp.iterrows():
                if prevRow is not None:
                    if 'write' in prevRow['function_name'] and (row['function_name'] == 'fsync'):
                        count += 1
                prevRow = row
        
        num_write = len(df[df['function_name'].str.contains('write')])
        print(count)
        print(num_write)
        return count / num_write > 0.5

    def isFilePerProc(self):
        return self.is_shared_io()
